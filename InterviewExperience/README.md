# C++

## 关键字与运算符

#### 指针与引用

1. 指针存放的是某个对象的地址，指针本身就是一个变量，也有地址，所以存在指向指针的指针，既可以改变指针的指向，也可以通过指针改变指针指向的内容
2. 引用就是变量的别名，必须初始化，并且不能改变
3. 存在指针空值的空指针，不存在指向空值的空引用

#### define和typedef的区别

**define**

> 1. 只是简单的字符串替换，没有类型检查
> 2. 在预处理阶段起作用：进行替换
> 3. 不分配内存，给的是立即数，有多少次使用就进行多少次替换(预处理阶段)

**typedef**

> 1. typedef定义了一个新的数据类型，进行类型检查
>     ~~~C++
>     typedef char* PSTR;
>     int mystrcmp(const PSTR, const PSTR);
>     const PSTR != const char*;
>     const PSTR == char* const;
>     ~~~
>
>     
>
> 2. 在编译的时候起作用
>
> 3. typedef定义出来的是变量，分配内存空间，在程序运行过程中内存里只有一个拷贝

#### define和inline的区别

**define**

> define宏是字符串替换，无类型检查，不安全

**inline**

> 1. C++的建议型关键字，编译器可以拒绝
>
> 2. 内联函数是⼀种特殊的函数，会进⾏类型检查
> 3. `inline`函数与普通函数的区别在于，当编译器处理调用内联函数的语句时，不会将该语句编译成函数调用的指令，而是**直接将整个函数体的代码插人调用语句处**，就像整个函数体在调用处被重写了一遍一样。**中心思想是以空间换时间**

# 面经

## 1

### C++

###### volatile

> 保证内存可⻅性。
>
> - 可⻅性是指线程之间的可⻅性，⼀个线程修改的状态对另⼀个线程是可⻅的。也就是⼀个线程修改的结果，另⼀个线程⻢上就能看到。
>
> 实现原理： 
>
> - （1）当对⾮volatile变量进⾏读写的时候，每个线程先从主内存拷⻉变量到CPU缓存中，如果计算机有多个CPU， 每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷⻉到不同的CPU cache中。   
> - （2）volatile变量不会被缓存在寄存器或者对其他处理器不可⻅的地⽅，保证了每次读写变量都从主内存中读，跳过CPU cache这⼀步。当⼀个线程修改了这个变量的值，新值对于其他线程是⽴即得知的。 

### OS

###### 进程与线程的区别，进程通信方式

> 进程是系统资源的最小分配单位，创建进程需要分配地址空间+PCB(process control block)资源，切换复杂
>
> 线程是CPU调度的最小单位，创建线程只需要分配PCB资源，切换简单
>
> 并且，LINUX，进程与线程都是轻量级进程
>
> 进程的通信方式有：较熟悉的有管道，共享内存，不了解的有消息队列

###### 多进程与多线程的区别以及使用场景

> | 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
> | -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
> | 数据共享，同步 | 数据共享复杂，需要使用IPC；数据独立，同步简单                | 因为共享进程数据，数据共享简单，但因此导致同步复杂           | 各有优势 |
> | 内存，CPU      | 占用内存多(每个进程都需要分配进程地址空间)，切换复杂，CPU利用老板低 | 占用内存少(多个线程共用一个进程地址空间)，切换简单，CPU利用率高 | 线程占优 |
> | 创建/销毁/切换 | 创建/销毁/切换复杂，速度慢(创建进程分配的资源多)，原因有：切换PCB，加载内存，打开文件 | 创建/销毁/切换简单，速度快，原因有：仅需要切换PCB，替换寄存器内容，栈内容 | 线程占优 |
> | 可靠性         | 进程间不会互相影响，稳定性高                                 | 一个线程出错会导致整个进程挂掉，稳定性差                     | 进程占优 |
> | 编程/调试      | 编程简单，调试简单                                           | 编程复杂，调试复杂，原因有：线程安全，资源共享               | 进程占优 |
> | 分布式         | 适用于多核多机                                               | 适用于多核                                                   |          |
> | 使用场景       | 系统稳定性要求严格：自动驾驶                                 | 大量计算任务(计算密集)；桌面软件(IO密集)；Web服务器          |          |
>
> [多线程和多进程 及其应用场景_多线程、多进程在实际工程中的用处](https://blog.csdn.net/weixin_39731083/article/details/82015830)
>
> 多进程的优点：
>
> 1. **编程相对容易**；通常不需要考虑锁和同步资源的问题。 
> 2. **更强的容错性**：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。 
> 3. **有内核保证的隔离：数据和错误隔离**。 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。
>
> 多线程的优点：
>
> 1. **创建速度快，方便高效的数据共享** 
>     共享数据：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术。
> 2. **较轻的上下文切换开销** - 不用切换地址空间，不用更改寄存器，不用刷新TLB。 
> 3. **提供非均质的服务**。如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降
>
> 选什么？
>
> 1. **需要频繁创建销毁的优先用线程（进程的创建和销毁开销过大）**
>     这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的
> 2. **需要进行大量计算的优先使用线程（CPU频繁切换）**
>     所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。
>     这种原则最常见的是图像处理、算法处理。
> 3. **强相关的处理用线程，弱相关的处理用进程**
>     什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。
>     一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。
>     当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。
> 4. **多机分布的用进程，多核分布的用线程**
> 5. 一个选择原则：如果多进程和多线程都能够满足要求，那么选择你最熟悉、最拿手的那个。

### 计网

###### http和https的区别

> **端口**
>
> > HTTP的URL由`http://`起始且默认使用端口80
> >
> > HTTPS的URL由`https://`起始且默认使用端口443
>
> 安全性和资源消耗
>
> > HTTP协议运行在TCP(UDP)之上，传输的内容都是明文，客户端和服务器端都无法验证对方的身份
> >
> > HTTPS协议是运行在SSL/TLS之上的HTTP协议，SSL/TLS协议运行在TCP之上，传输的内容都是经过加密的，加密采用 CA认证+签名+非对称加密+对称加密 
> >
> > HTTP安全性没有HTTPS高，但是消耗的服务器资源比HTTPS低(加密解密都需要消耗资源)

###### HTTPS用到了那些加密技术

> 对称加密
>
> > 密钥只有一个，既可以加密也可以解密，且加密解密速度快，典型有：DES，AES
>
> 非对称加密
>
> > 密钥成对出现，分为公钥和私钥。加密解密使用不同密钥(私钥加密只能由公钥解密，公钥加密只能由私钥加密)，相对对称加密速度较慢，典型有：RSA，DSA
>
> CA认证签名+非对称加密+对称加密
>
> > 服务器向CA机构申请得到CA私钥加密后的证书，该证书里有服务器公钥
> >
> > 客户端链接服务器时会得到服务器的CA证书，使用公布的CA公钥来验证该证书的合法性
> >
> > 若证书合法，则证书里的服务器公钥要是合法的，此时客户端使用该公钥加密自己的对称密钥，返回给服务器
> >
> > 服务器得到后使用服务器私钥解密，这样CS都具有对称密钥，使用该密钥进行加密解密

###### 打开一个网页使用到了哪些协议？

> [一次完整的HTTP请求过程是怎么样的呢？](https://zhuanlan.zhihu.com/p/161560683)
>
> 概述
>
> > 1. **浏览器进行DNS域名解析，得到对应的IP地址**
> > 2. **根据这个IP，找到对应的服务器建立连接（三次握手）**
> > 3. **建立TCP连接后发起HTTP请求（一个完整的http请求报文）**
> > 4. **服务器响应HTTP请求，浏览器得到html代码（服务器如何响应）**
> > 5. **浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）**
> > 6. **浏览器对页面进行渲染呈现给用户**
> > 7. **服务器关闭TCP连接（四次挥手）**
> > 8. **还可能用到ARP，NAT，ICMP协议**
>
> 详情
>
> > DNS查找IP：浏览器缓存，OS缓存，hosts文件，DNS服务器
> >
> > TCP协议：三次握手
> >
> > IP协议：路由转发
> >
> > HTTP协议：HTTP请求/响应
> >
> > ARP协议：IP转MAC地址
> >
> > NAT协议：IP转换
> >
> > ICMP协议：错误审查

###### DNS过程详情

> 域名的解析是⼀个从右向左的过程，并且域名都隐藏了一个默认的根域名服务器`.`
>
> `. -> .com -> google.com. -> www.google.com . `
>
> - 首先会在**浏览器的DNS缓存**中去查询是否有对应的记录，如果查询到记录就可以直接得到对应的IP地址，则完成解析。
> - 如果在浏览器的DNS缓存中没有找到，就会去查询**操作系统中的DNS缓存**，如果查询到对应的IP地址，则完成解析。
> - 如果在操作系统的DNS缓存中没有找到，就会去查找**本地的hosts文件**，如果查询到对应的IP地址，则完成解析。
> - 如果在本地的hosts文件中也没有找到，就会去**本地DNS服务器**中查找。本地DNS服务器IP地址一般由本地网络服务商提供，如电信、移动等公司，一般通过DHCP自动分配。目前使用的比较多的是谷歌提供的公用NDS 8.8.8.8和国内公用DNS 114.114.114.114。如果在本地DNS服务器中有对应域名的缓存，直接返回对应的IP地址，则完成解析。
> - 如果本地DNS服务器中仍然没有找到，那么本地DNS服务器就会拿着域名去**根DNS服务器**中询问，根DNS服务器会告诉本地DNS顶级域名服务器的IP地址。
> - 本地DNS拿到顶级域名服务器的IP地址后，就会拿着域名去找**顶级DNS服务器**，顶级域名服务器会告诉本地DNS权威域名服务器的IP地址。
> - 本地DNS服务器拿着域名去**权威域名服务器**中，查询域名对应的IP地址，最终将该域名对应的IP地址返回给浏览器，此时整个域名解析过程就完成了。

###### TCP四次挥⼿中，time-wait状态，close-wait状态，在哪⼀个阶段？

> 四次挥手
>
> > 1. 客户端发送 FIN
> >     
> >
> > 2. 服务器返回 ACK 号
> >
> >     
> >
> > 3. 服务器发送 FIN   
> >
> > 4. 客户端返回 ACK 号  
>
> 状态变化(建议画图)
>
> > 客户端发送FIN：⽤来申请关闭客户端到服务器的数据传送，此时 客户端进⼊**FIN_WAIT_1状态**，等待服务器发送ACK
> >
> > 服务器收到FIN：服务器收到客户端发送的FIN后，就会进入**CLOSE_WAIT状态**
> >
> > 服务器发送ACK：告知客户端自己收到了C->S链接断开的请求，此时 客户端发送服务器读取的链接关闭
> >
> > 客户端收到ACK：客户端进入**FIN_WAIT_2状态**，此时 客户端发送服务器读取的链接关闭
> >
> > 
> >
> > 服务器发送FIN：⽤来申请关闭服务器到客户端的数据传送，此时服务器进入**LASE_ACK状态**，等待客户端发送最后的ACK
> >
> > 客户端收到FIN：客户端收到服务器断开链接请求，客户端进入**TIME_WAIT状态**，并发送一个ACK
> >
> > 客户端发送ACK：等待两个MSL时间关闭S->C链接，然后关闭服务器发送客户端读取的链接
> >
> > 服务器收到ACK：关闭服务器发送客户端读取的链接
> >
> > 服务器没收到ACK：重新发送FIN
>
> ![image-20230724113908431](%E5%9B%BE%E7%89%87/README/image-20230724113908431.png)

###### TCP粘包拆包

> 包：应用层数据包
>
> 产生粘包的原因：
>
> > 应用层交给TCP的数据，是先放在TCP发送缓冲区，再由TCP协议控制发送的。而TCP发送数据时依赖滑动窗口，这就导致在发送时，数据报不一定是一个应用层数据包。
> >
> > 那么TCP接收端在接收到数据时，因为是面向字节流+没有报文长度字段，导致接收端也无法分辨是否是一个数据包，只能按照32位序列号进行排序。
> >
> > 在应用层读取时，需要从TCP接收缓冲区读取，TCP是面向字节流的，导致应用层读到的是一串数据，这些数据不能保证正正好好是一个数据包，只能保证宏观上有序。
> >
> > TCP的读取和发送是有水位线概念的，到达一定字节时，才允许从TCP读取和发送，粘包也能解决频繁IO。
>
> 如何解决粘包问题：
>
> > 粘包问题是在应用层解决的，一可以通过协议表明一个数据包的长度，二可以明确数据包之间的分隔标识，通过标识切割。
> >
> > 如HTTP解决粘包问题使用的是 定长报头+正文长度字段 来保证读取一个完整HTTP数据包。

###### TCP拥塞控制和流量控制的区别

> 拥塞控制是对整个通信网络来说的，避免过多的数据注入到网络中，使网络拥塞进而大量丢包，拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低⽹络传输性能有关的所有因素。
>
> 流量控制是对一条TCP通信链接来说的，是个端到端的问题，控制发送数据速率，确保接收端来得及接收。
>
> 发送窗口受制于拥塞控制和流量控制。

### 笔试

[剑指 Offer 04. 二维数组中的查找 - 力扣（LeetCode）](https://leetcode.cn/problems/er-wei-shu-zu-zhong-de-cha-zhao-lcof/)