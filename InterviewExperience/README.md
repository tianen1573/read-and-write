# C++

#### 指针与引用

> 1. 本质: 指针是一个变量，存储内容是一个地址，指向内存的一个存储单元。而引用是原变量的一个别名，实质上和原变量是一个东西，是某块内存的别名。
> 2. 指针的值可以为空，且非const指针可以被重新赋值以指向另一个不同的对象。而引用的值不能为空，并且引用在定义的时候必须初始化，一旦初始化，就和原变量“绑定”，不能更改这个绑定关系。
> 3. 对指针执行sizeof()操作得到的是指针本身的大小（32位系统为4,64位系统为8）。而对引用执行sizeof()操作得到的是所绑定的对象的所占内存大小。
> 4. 指针的自增(++)运算表示对地址的自增，自增大小要看所指向单元的类型。而引用的自增(++)运算表示对值的自增。
> 5. 在作为函数参数进行传递时的区别: 指针作为函数形参时，函数内部的指针形参是指针实参的一个副本，改变指针形参并不能改变指针实参的值，可以通过解引用*运算符来更改指针所指向的内存单元里的数据。而引用在作为函数参数进行传递时，实质上传递的是实参本身，即传递进来的不是实参的一个拷贝，因此对形参的修改其实是对实参的修改，所以在用引用进行参数传递时，不仅节约时间，而且可以节约空间。

#### define和typedef

**define**

> 1. 只是简单的字符串替换，没有类型检查
> 2. 在预处理阶段起作用：进行替换
> 3. 不分配内存，给的是立即数，有多少次使用就进行多少次替换(预处理阶段)

**typedef**

> 1. typedef定义了一个新的数据类型，进行类型检查
>     ~~~C++
>     typedef char* PSTR;
>     int mystrcmp(const PSTR, const PSTR);
>     const PSTR != const char*;
>     const PSTR == char* const;
>     ~~~
>
>     2. 在编译的时候起作用
>
> 3. typedef定义出来的是变量，分配内存空间，在程序运行过程中内存里只有一个拷贝

#### define和inline

**define**

> define宏是字符串替换，无类型检查，不安全

**inline**

> 1. C++的建议型关键字，编译器可以拒绝
>
> 2. 内联函数是⼀种特殊的函数，会进⾏类型检查
> 3. `inline`函数与普通函数的区别在于，当编译器处理调用内联函数的语句时，不会将该语句编译成函数调用的指令，而是**直接将整个函数体的代码插人调用语句处**，就像整个函数体在调用处被重写了一遍一样。**中心思想是以空间换时间**
> 4. 都是将代码插入的调用处，但inline是建议性的，并且有类型检查。
> 5. C++中inline编译限制
>
>     > 1. 不能存在任何形式的循环语句 
>     > 2. 不能存在过多的条件判断语句 
>     > 3. 函数体不能过于庞⼤ 
>     > 4. 内联函数声明必须在调⽤语句之前

#### 重载/重写/隐藏

>  ![image-20230726090406380](%E5%9B%BE%E7%89%87/README/image-20230726090406380.png)
>
> 重载：
>
> > - 在同一个作用域下，函数名相同，形参列表不同，则这些同名函数构成重载
> > - 不能根据返回值类型，访问权限判断两个函数是否构成重载
> > - 重载属于静态多态，即在编译阶段，就已经确定了调用哪一个重载函数
>
> 隐藏(重定义)：
>
> > - 在不同作用域下(父类，子类)，函数名相同的两个函数构成隐藏(重定义)
> > - 当两个函数构成隐藏时，父类的同名函数会被隐藏，当用子类的对象调用同名函数时，若不指定类作用符，默认调用子类的同名函数
> > - 同名成员对象也构成隐藏
>
> 重写(覆盖)：
>
> > - 在不同作用域下(父类，子类)，函数的函数名，形参列表，返回值类型完全相同，且父类必须指明virtual
> >
> > - 重写的两个例外：(1)析构函数为虚函数时，父子类的析构函数名不需要相同，但编译器对析构函数的名称做了特殊处理，编译后析构函数的名称统一处理成destructor；(2)协变，即基类虚函数返回基类对象的指针或者引用，派生类虚函数返回派生类对象的指针或者引用时，称为协变，此时返回值类型不同，但也构成重写。
> > - 构造函数和静态函数不能定义为虚函数，前者在对象构造完成前调用，不存在vptr；后者没有this指针，找不到对象的vptr

#### 基类析构函数为什么要定义为虚函数？

> 当基类指针指向派生类对象时，若基类的析构函数不定义为虚函数，则通过基类指针析构时，只会调用基类的析构函数而不会调用派生类的析构函数，此时派生类部分的内存就没有释放，从而导致内存泄漏
>
> 即，**保护派生类资源安全释放**

#### 构造函数为什么不能为虚函数？

> **和虚函数的调用逻辑有关**
>
> - 如果一个函数为虚函数，调用该函数，需要经过this指针找到虚函数表指针vptr，再通过vptr找到虚函数表，最后从虚函数表查找该虚函数对应的地址进行调用
> - 而vptr是在分配对象内存时生成的，即构造函数列表初始化阶段，此时属于调用了构造函数，但构造对象动作还未完成
> - 如果把构造函数定义为虚函数，则构造对象时需要先找到vptr，而vptr需要先构造才放入内存空间，逻辑矛盾

#### 浅拷贝与深拷贝

> - 深拷贝(Memberwise copy semantics)：需要自己按照真实逻辑自写拷贝代码，使源对象与拷贝对象互相独立，其中任何一个对象的改动都不会对另外一个对象造成影响
> - 浅拷贝(bitwise copy semantics)：又叫值拷贝，拷贝逻辑为仅仅按字节拷贝，可能导致源对象与拷贝对象可能指向了同一份资源，从而导致资源泄漏
> - 浅拷贝在类里面有指针成员的情况下只会复制指针的地址，会导致两个成员指针指向同一块内存，这样在要是分别delete释放时就会出现问题，因此需要用深拷贝
> - 如果在类中没有显式地声明一个拷贝构造函数，那么，编译器将会自动生成一个默认的拷贝构造函数，该构造函数完成对象之间的浅拷贝

#### C++如何避免内存泄漏

> - 使用RAII思想，通过栈对象的构造函数(申请资源)与析构函数(释放资源)，来管理资源
> - 相比于原生指针，推荐使用智能指针，如C++11的share_ptr，unique_ptr
> - 注意new/delete和new[]/delete[]的匹配使用
> - 完善类的拷贝构造，赋值重载构造函数，避免发生危险的浅拷贝，导致动态资源泄漏

#### C++静态变量初始化

> 在C++中，静态变量分为全局静态变量（又称全局变量）、局部静态变量（函数中的静态变量）和类中静态成员变量。按照初始化的类型分为静态初始化（static initialization）和动态初始化(dynamic initialization)
>
> 全局变量、文件域的静态变量和类的静态成员变量**在main执行之前的静态初始化过程中分配内存并初始化**；
>
> 局部静态变量（一般为函数内的静态变量）在**第一次使用时分配内存并初始化**。这里的变量包含内置数据类型和自定义类型的对象。
>
> **全局静态变量/全局变量/类的静态成员变量**
>
> > - **程序加载前初始化**，即编译时就已经初始化，分为静态初始化和动态初始化。
>
> **局部静态变量**
>
> > - C语言中，和全局静态变量一样，程序加载前初始化
> > - C++中，**在执行相关代码时才会进行初始化**，主要是由于C++引入对象后，要进行初始化必须执行相应构造函数和析构函数，在构造函数或析构函数中经常会需要进行某些程序中需要进行的特定操作，并非简单地分配内存。**所以C++标准定为全局或静态对象是有首次用到时才会进行构造，并通过atexit()来管理。在C++中是可以使用变量对静态局部变量进行初始化的**
>
> 根据 C++ 标准，全局变量的初始化要在 main 函数执行前完成，常识无疑，但是这个说法有点含糊，main 函数执行前到底具体是什么时候呢？是编译时还是运行时？**答案是既有编译时，也可能会有运行时(seriously)**
>
> **静态初始化**
>
> > 静态初始化指的是用常量来对变量进行初始化,主要包括 zero initialization 和 const initialization，**静态初始化在程序加载的过程中完成**，对简单类型(内建类型，POD等)来说，从具体实现上看，zero initialization 的变量会被保存在 bss 段，const initialization 的变量则放在 data 段内，程序加载即可完成初始化，这和 c 语言里的全局变量初始化基本是一致的。
>
> **动态初始化**
>
> > 动态初始化主要是指需要经过函数调用才能完成的初始化，比如说：int a = foo()，或者是复杂类型（类）的初始化（需要调用构造函数）等。这些变量的初始化会**在 main 函数执行前由运行时调用相应的代码从而得以进行**(函数内的 static 变量除外)。
>
> ~~~C++
> class A
> {
> public:
> 	A()
> 	{
> 		cout << "I am A" << endl;
> 	}
> 	A(const A&a)
> 	{
> 		cout << "I am A : a" << endl;
> 	}
> 	~A()
> 	{
> 		cout << "I am ~A" << endl;
> 	}
> };
> class B
> {
> public:
> 	B()
> 	{
> 		cout << "I am B" << endl;
> 	}
> 	~B()
> 	{
> 		cout << "I am ~B" << endl;
> 	}
> 	static A a;
> };
> A B::a; // 1
> 
> int func()
> {
> 	static B b; // 3
> 	return 1;
> }
> int aaaa = func(); // 4
> B bb; // 2
> int main()
> {
> 	cout << "main()" << endl;
> 
> 	A aa;
> 	static A aaa = aa; // 5
> 	//func();
> 
> 	cout << "~main()" << endl;
> 	return 0;
> }
> ~~~

#### new和malloc有什么区别

> - new是C++操作符，malloc是C语言函数
>
> - 申请内存的所在位置：new操作符从自由存储区(free store)上为对象动态分配内存空间，而malloc函数从堆上动态分配内存空间
>
> - 返回类型安全：new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全的操作符；而malloc内存分配成功返回的是void*，需要通过强制类型转换将指针转换成我们需要的类型
>
> - 内存分配失败时的返回值：new内存分配失败时，会抛出bad_alloc异常，它不会返回NULL；而malloc内存分配失败时返回NULL
>
> - 是否需要指定内存大小(是否需要"参数")：使用new操作符申请内存时无需指定内存块的大小，编译器会根据类型自行计算；而malloc则需要显示地指出所需内存的尺寸
>
> - 是否调用构造函数：new会调用对象的构造函数，在分配内存后完成对象初始化；而malloc不会，仅仅分配内存
>
> - 对数组的处理：C++提供了new[]和delete[]，可以指定变量个数；malloc并不知道你申请的内存是分配给一个变量还是一个数组，仅仅给你指定大小内存的首地址。前者指定数组元素个数，后者指定数组内存大小
>
> - new与malloc是否可以相互调用：new底层调用operator new全局函数，而operator new的实现默认基于malloc
>
> - 是否可以被重载：operator new/delete 可以被重载，malloc/free不能重载
>
> - 是否可以重新分配内存：使用malloc分配的内存可以使用realloc函数重新分配内存，进行缩/扩容；而new不可以
>
> - 客户处理内存分配不足: 在operator new抛出异常以反映一个未获得满足的需求之前，它会先调用一个用户指定的错误处理函数，这就是new-handler。 对于malloc，客户并不能够去编程决定内存不足以分配时要干什么事，只能看着malloc返回NULL。
>
>     | 特征                 | new/delete                       | malloc/free            |
>     | -------------------- | -------------------------------- | ---------------------- |
>     | 分配内存的位置       | 自由存储区                       | 堆                     |
>     | 内存分配成功的返回值 | 完整类型指针                     | void*                  |
>     | 内存分配失败的返回值 | 默认抛出异常                     | 返回NULL               |
>     | 分配内存的大小       | 编译器根据类型自行计算           | 作为参数显示指定大小   |
>     | 已分配内存的扩充     | 无法直观地处理                   | realloc函数            |
>     | 分配内存时内存不足   | 能够指定处理函数或重新制定分配器 | 无法通过用户代码处理   |
>     | 处理数组             | new[]/delete[]指定元素个数       | malloc指定数组字节大小 |
>     | 是否相互调用         | new默认最终调用malloc            | 不可调用new            |
>     | 函数重载             | operator new 可重载              | 不可重载(C语言)        |
>     | 构造函数与析构函数   | 调用：完成对象的初始化与资源释放 | 不调用                 |
>
>     **自由存储区是C++基于 operator new 的一个抽象概念，凡是通过 operator new 申请的内存，即为自由存储区。**而堆是计算机操作系统的术语，是操作系统所维护的一块特殊内存，用于程序内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的相应内存。
>
>     [【C++学习笔记】new与malloc的区别](https://www.cnblogs.com/phillee/p/11707575.html#:~:text=operator new 从自由存储区上为对象动态分配内存空间，而 malloc 从堆上动态分配内存。 自由存储区是C%2B%2B基于,operator new 的一个抽象概念，凡是通过 operator new 申请的内存，即为自由存储区。)

#### const 关键字

> 修饰变量
>
> > 1、const修饰的量不是常量，仅仅**是个只读量**。在**编译的时候全部替换const变量被赋予的值**（这点和C语言的宏相似），在运行的时候该const变量可通过内存进行修改
> >
> > - 通过内存(指针)可以修改位于栈区的const变量，语法合乎规定，编译运行不会报错，但是在编译的时候所有用到该常量的地方全部被替换成了定义时所赋予的值，然后再运行的时候无法使用通过指针修改后的值**(a 和  *pa 是不同的值)**。
> >
> > - 通过内存(指针)修改**位于静态存储区的的const变量**，语法上没有报错，编译不会出错，**一旦运行就会报告异常(没有写入权限)**。
> >
> > **注：通过指针修改在全局区上的const变量，编译可通过，运行就会报异常。**
> >
> > 2、const volatile修饰的变量，可以在编译时不用全部替换为const volatile变量被赋予的值，因此可以在运行时使用通过内存修改后的值
> >
> > - 通过内存(指针)可以修改位于栈区的const volatile变量，语法合乎规定，编译运行不会报错，在编译的时候所有用到该常量的地方不会替换成了定义时所赋予的值，在运行的时候可以使用通过指针修改后的值**(取消了编译器优化)**。
> >
> > - 通过内存(指针)修改位于静态存储区的的const volatile变量，语法上没有报错，编译不会出错，**一旦运行就会报告异常(没有写入权限)**。
> >
> > 3、**const变量的内存位于栈区或者静态存储区，不在符号表(常量表)中**：众说纷纭，我也不知
>
> 修饰指针
>
> > - 常量指针：常量的指针，修饰的是指针指向的内容，不能通过该指针修改指向的内容，但可以修改指针的指向
> > - 指针常量：指针是常量，修饰的是指针本身，不能修改指针的指向，但可以通过该指针修改其指向的内容
> > - 常量指针常量：既不可以修改指针的指向，也不可以通过指针修改其指向的内容
>
> 修饰成员函数
>
> > 本质上修改隐藏的this指针，在该函数内不能通过this指针修改对象的成员变量，也只能调用同样是const的成员函数

#### 拷贝构造函数的参数必须是引用类型

> 如果拷贝构造函数的参数不是引用类型，即形如CClass(const CClass t)，那么就是采用了值传递的方式，而值传递传参会调用该类的拷贝构造函数，从而造成**无穷递归地调用拷贝构造函数**，因此拷贝构造函数的参数必须是引用类型。
>
> 在C++中，有下面三种情况会进行拷贝构造：
>
> - 一个对象以值传递的方式传入函数体。
> - 一个对象以值传递的方式从函数返回。
> - 一个对象需要通过另一个对象进行初始化。
>
> 当类中的数据需要动态分配存储空间时，必须显示实现拷贝构造函数，因为默认拷贝构造函数是基于值拷贝的，即按字节拷贝。此时默认拷贝构造函数会使多个对象指向同一份动态内存空间，从而造成内存泄漏。

#### STL迭代器失效

> [STL 容器迭代器失效总结(超级详细)_xupeng1644的博客](https://blog.csdn.net/xp178171640/article/details/104905338)
>
> 原迭代器指的是进行操作之前保存的迭代器，包括begin()、end()以及其他位置的迭代器。
>
> **vector：**
>
> > 底层是数组
> >
> > - 成员函数`push_back()`：会在容器末尾添加一个元素。如果容器有剩余空间(capacity() > size())，则直接添加新元素到容器尾部。此时，**原迭代器中end()会失效**，其他的都不会失效。否则，会导致容器重新分配内存，然后将数据从原内存复制到新内存，再在尾部添加新元素。此时，由于内存重新分配，**原迭代器(所有)都失效**。
> > - 成员函数`pop_back()`：直接将容器中的最后一个元素删除，**原迭代器中end()会失效**，其余的都不会失效。
> >
> > - 成员函数`insert(iterator, n)`：如果容器有剩余空间，先在容器尾部插入一个元素，然后将插入点及之后的元素都向后移动一位，然后在插入点创建新元素。否则，会导致容器重新分配内存，接着将插入点之前的元素复制过去，在插入点创建新元素，再将插入点之后的元素复制过去。因此，如果没有内存的重新分配，**原迭代器中插入点及插入点之后的迭代器(包括end())都失效**。如果有内存的重新分配，**原迭代器(所有)都失效**。
> >
> > - 成员函数`erase(iterator)`：将删除点及之后的元素都向前移动一位，然后删除最后一个元素。因此，原迭代器中删除点之前的迭代器都有效，**插入点及插入点之后的迭代器都失效**。
>
> **deque:**
>
> > 底层好像是多个数组
> >
> > - 成员函数`push_back()`：会直接在容器末尾添加一个元素。**原迭代器中end()会失效**，其他的都不会失效。
> >
> > - 成员函数`push_front()`：会直接在容器头部添加一个元素。**原迭代器中begin()会失效**，其他的都不会失效。
> >
> > - 成员函数`pop_back()`：会直接删除最后一个元素。**原迭代器中end()会失效**，其他的都不会失效
> >
> > - 成员函数`pop_front()`：会直接在容器头部删除一个元素。**原迭代器中begin()会失效**，其他的都不会失效。
> >
> > - 成员函数`insert(iterator, n)`：如果插入点之前的元素较少，会在容器头部插入一个元素，然后将插入点及其之前的所有元素向前移动一位，再在插入点创建新元素。否则，将插入点及其之后的元素向后移动一位，再在插入点创建新元素。因此，**向前移动则导致原迭代器中插入点及插入点之前的迭代器都失效；向后移动则导致迭代器中插入点及插入点之后的迭代器都失效**。
> >
> > - 成员函数`erase(iterator)`：如果删除点之前的元素较少，将删除点之前的所有元素向后移动一位，再删除第一个元素。否则，将删除点之后的所有元素向前移动一位，再删除最后一个元素。因此，**向前移动将导致原迭代器中删除点及删除点之后的迭代器失效；向后移动将导致原迭代器中删除点及删除点之前的迭代器都失效**。
>
> **list:**
>
> > 底层是双向链表
> >
> > - 因为list的底层结构是双向链表，所有操作都只是针对节点移动指针，不会涉及到位置变化，操作影响的范围很小。
> >
> > - 成员函数`push_back()`：**原迭代器中end()会失效**，其他的都不会失效。
> >
> > - 成员函数`push_front()`：**原迭代器中begin()会失效**，其他的都不会失效。
> >
> > - 成员函数`pop_back()`：**原迭代器中end()会失效**，其他的都不会失效
> >
> > - 成员函数`pop_front()`：**原迭代器中begin()会失效**，其他的都不会失效。
> >
> > - 成员函数`insert(iterator, n)`：**原迭代器中插入点会失效**，其他的都不会失效。
> >
> > - 成员函数`erase(iterator)`：**原迭代器中删除点会失效**，其他的都不会失效。
>
> **set、multiset、map、multimap**
>
> > 关联容器的底层结构为红黑树，所有操作同list一样，都只是移动指针，各成员函数导致的迭代器失效问题同list。
>
> 注意：文中成员函数的内部实现以SGI STL为准。和容器的底层数据结构，底层实现相关重大。

#### 为什么内联函数，构造函数，静态成员函数不能为virtual函数？

> **内联函数**
>
> > 内联函数会在编译阶段展开，而虚函数是在运行时动态执行，两者相矛盾，但inline是建议性关键字，作为虚函数时编译器会忽略掉inline建议。
>
> **构造函数**
>
> > 构造函数的功能是申请空间+初始化对象，而虚函数的运行是建立在对象的基础上的，执行到构造函数函数体时才完成对象的初始化，这个时候才有理论上调用虚函数的基础，和构造函数的调用时机矛盾，产生先有鸡还是先有蛋的矛盾。
>
> **静态成员函数**
>
> > 虚函数的调用依赖对象空间保存的虚指针，而静态成员函数属于类没有this指针，找不到对象空间。
>
> **友元函数**
>
> > C++不支持友元函数的继承，对于没有继承性的函数没有虚函数。
> >
> > virtual意味着在执行时期进行绑定，所以在编译时刻需要确定信息的不能为virtual。
> >
> > virtual意味着派生类可以改写其动作。

#### C++虚函数表和虚指针

> C++的多态是基于虚函数+继承实现的，通过运行时决策来实现多态。
>
> 运行时决策是通过虚指针和虚函数表实现的，找到真正应该调用的函数，从而实现多态。
>
> 虚函数表是属于类的，存在只读数据段；虚指针是属于对象的，对象通过该指针找到虚函数表。
>
> 如果一个函数是虚函数，那么调用步骤就是：首先通过this指针找到对象空间，然后找到虚指针，之后通过虚指针找到虚函数表，从虚函数表找到对应函数的地址，调用该函数。
>
> **虚函数表的来源**
>
> > 非继承的类:
> >
> > - 如果一个类中有虚函数，则该类就有一个虚函数表。`虚函数表是属于类的，不属于类对象。在编译的时候确定，存放在只读数据段`。
> > - 每一个实例化的类对象都有一个虚函数表指针，指向类的虚函数表。虚函数表指针属于类对象。存放在对象空间。
> >
> > 单继承的类:
> >
> > - 如果基类中有虚函数，派生类实现或没实现，都有虚函数表。基类的虚函数表和派生类的虚函数表不是同一个表。
> > - 如果派生类没有重写基类的虚函数，则派生类的虚函数表和基类的虚函数表的内容是一样的。
> > - 如果派生类重写了基类的虚函数，则在派生类的虚函数表中用的是派生类的函数。
> >
> > 多继承:
> >
> > - 含有虚函数的基类有多少个，派生类就有多少个虚函数表指针，派生类有就有多少个虚函数表。
> > - 派生类有的而基类没有的虚函数，添加在第一个虚函数表中。
> > - 虚函数表的结果是* 表示还有下一个虚函数表
> > - 虚函数表的结果是0 表示是最后一个虚函数表
>
> 使用虚函数，系统要有一定量的空间开销。当一个类带有虚函数时，编译系统会为这个类构造一个虚函数表，他是一个指针数组，存放每个虚函数的入口地址。无论该虚函数是否进行重写，都会进行运行时决策。

#### 构造函数可以调用虚函数吗

> 语法上可行，但达不到多态效果。
>
> 在单继承体系中，构造派生类时，会先调用基类的构造函数，构造基类。此时整个对象是存在一个虚指针的，指向的是基类的虚函数表，那么基类的构造函数调用某个虚函数，指向的是基类的函数，不会指向派生类的；当调用派生类的构造函数时，虚指针会指向派生类的虚函数表，此时派生类的构造函数调用某个虚函数，指向的是派生类的函数。
>
> 析构函数是同样的道理，构造/析构函数调用虚函数，达不到多态效果。

#### volatile

> 保证内存可⻅性。
>
> - 可⻅性是指线程之间的可⻅性，⼀个线程修改的状态对另⼀个线程是可⻅的。也就是⼀个线程修改的结果，另⼀个线程⻢上就能看到。
>
> 实现原理： 
>
> - （1）当对⾮volatile变量进⾏读写的时候，每个线程先从主内存拷⻉变量到CPU缓存中，如果计算机有多个CPU， 每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷⻉到不同的CPU cache中。   
> - （2）volatile变量不会被缓存在寄存器或者对其他处理器不可⻅的地⽅，保证了每次读写变量都从主内存中读，跳过CPU cache这⼀步。当⼀个线程修改了这个变量的值，新值对于其他线程是⽴即得知的。 

#### C++类成员的访问权限

> C++通过public、protected、private三个关键字来控制成员变量和成员函数的访问权限，分别是共公有的，受保护的，私有的。
>
> - 在类的内部：没有访问权限的限制
> - 在类的外部：只能通过对象访问成员，且只能访问对象的public成员，其他权限的成员不能访问
>
> 在继承体系中，权限变化如下
>
> - ![image-20230808082409324](%E5%9B%BE%E7%89%87/README/image-20230808082409324.png)
> - 子类中父类成员的保护级别 = min{父类中的保护级别，继承方式}
>
> 当父类成员继承到子类中后，子类中的父类成员的访问权限如下
>
> - ![image-20230808082713719](%E5%9B%BE%E7%89%87/README/image-20230808082713719.png)

#### C++ class和struct的区别

> **默认访问权限不同**
>
> - 结构体的成员默认访问权限是public
>
> - C++类的成员默认访问权限是private
>
> **默认继承方式不同**
>
> - 结构体的默认继承方式为public
> - C++类的默认继承方式为private
>
> **模板**
>
> - class可以使用模板
> - struct不能使用

#### 类内静态变量在什么时候初始化

> 在C++中，静态变量分为全局静态变量（又称全局变量）、局部静态变量（函数中的静态变量）和类中静态成员变量。按照初始化的类型分为静态初始化（static initialization）和动态初始化(dynamic initialization)
>
> 全局变量、文件域的静态变量和类的静态成员变量**在main执行之前的静态初始化过程中分配内存并初始化**；
>
> 局部静态变量（一般为函数内的静态变量）在**第一次使用时分配内存并初始化**。这里的变量包含内置数据类型和自定义类型的对象。
>
> **全局静态变量/全局变量/类的静态成员变量**
>
> > - **程序加载前初始化**，即编译时就已经初始化，分为静态初始化和动态初始化
>
> **局部静态变量**
>
> > - C语言中，和全局静态变量一样，程序加载前初始化
> > - C++中，**在执行相关代码时才会进行初始化**，主要是由于C++引入对象后，要进行初始化必须执行相应构造函数和析构函数，在构造函数或析构函数中经常会需要进行某些程序中需要进行的特定操作，并非简单地分配内存。**所以C++标准定为全局或静态对象是有首次用到时才会进行构造，并通过atexit()来管理。在C++中是可以使用变量对静态局部变量进行初始化的**
>
> 根据 C++ 标准，全局变量的初始化要在 main 函数执行前完成，常识无疑，但是这个说法有点含糊，main 函数执行前到底具体是什么时候呢？是编译时还是运行时？**答案是既有编译时，也可能会有运行时(seriously)**
>
> **静态初始化**
>
> > 静态初始化指的是用常量来对变量进行初始化,主要包括 zero initialization 和 const initialization，静态初始化在程序加载的过程中完成，对简单类型(内建类型，POD等)来说，从具体实现上看，zero initialization 的变量会被保存在 bss 段，const initialization 的变量则放在 data 段内，程序加载即可完成初始化，这和 c 语言里的全局变量初始化基本是一致的。
>
> **动态初始化**
>
> > 动态初始化主要是指需要经过函数调用才能完成的初始化，比如说：int a = foo()，或者是复杂类型（类）的初始化（需要调用构造函数）等。这些变量的初始化会在 main 函数执行前由运行时调用相应的代码从而得以进行(函数内的 static 变量除外)。
>
> ~~~C++
> class A
> {
> public:
> 	A()
> 	{
> 		cout << "I am A" << endl;
> 	}
> 	A(const A&a)
> 	{
> 		cout << "I am A : a" << endl;
> 	}
> 	~A()
> 	{
> 		cout << "I am ~A" << endl;
> 	}
> };
> class B
> {
> public:
> 	B()
> 	{
> 		cout << "I am B" << endl;
> 	}
> 	~B()
> 	{
> 		cout << "I am ~B" << endl;
> 	}
> 	static A a;
> };
> A B::a; // 1
> 
> int func()
> {
> 	static B b; // 3
> 	return 1;
> }
> int aaaa = func(); // 4
> B bb; // 2
> int main()
> {
> 	cout << "main()" << endl;
> 
> 	A aa;
> 	static A aaa = aa; // 5
> 	//func();
> 
> 	cout << "~main()" << endl;
> 	return 0;
> }
> ~~~

#### 类内普通成员函数可以调用类内静态变量吗，类内静态成员函数可以访问类内普通变量吗？

> - 类内静态变量和类是相关的，非静态成员函数就可以通过this指针找到类，进而找到静态成员变量，也可以使用类作用符
>
> - 类内普通变量是和实例对象相关的，静态成员函数没有this指针，找不到实例对象，则也找不到非静态成员变量

#### 虚析构函数的作用

> **保证派生类资源的安全释放**
>
> 当基类指针指向派生类对象时，若基类的析构函数不定义为虚函数，则通过基类指针析构时，只会调用基类的析构函数而不会调用派生类的析构函数，此时派生类部分的内存就没有释放，从而导致内存泄漏。

#### vector存储的内容可以是引用吗?指针呢？

> **不可以是引用，可以是指针**
>
> **C++中不允许定义或声明指向引用的指针**，而STL库的容器如vector都需要实现迭代器，这些**迭代器的实现是依赖于底层数据的指针**的，所以底层数据类型是引用的话，会出现 引用的指针 **错误**

#### 类的多态如何实现

> - 派生类继承父类
> - 父类虚函数必须声明为virtual
> - 子类对应函数进行重写
> - 父类的指针或引用调用虚函数，根据实例对象的不同产生不同的效果

#### C/C++源文件生成可执行文件的过程

> **预处理、编译、汇编、链接**
>
> 1. 预处理阶段：对源文件中的#include、预编译语句(宏定义)进行分析和替换，生成预编译文件。产生.ii文件，参数为 -e。
> 2. 编译阶段：将预处理后的预编译文件转换成特定的汇编代码，生成汇编文件。产生.s文件，参数为 -s。
> 3. 汇编阶段：将编译阶段产生的汇编文件转换成机器码，生成可重定位目标文件。产生.o/.obj文件，参数为 -e。
> 4. 链接阶段：将多个目标文件及依赖库链接成最终的可执行目标文件。产生.exe文件。

#### 什么是右值引用，跟左值引用有什么区别

> 什么是左值？什么是左值引用？ 
>
> > 左值是一个表示数据的表达式(如变量名或解引用的指针)，我们**可以获取它的地址+可以对它赋值，左值可以出现赋值符号的左边，也能出现在赋值符号右边**。定义时const修饰符后的左值，不能给他赋值，但是可以取它的地址。左值引用就是给左值的引用，给左值取别名。
>
> 什么是右值？什么是右值引用？ 
>
> > 右值也是一个表示数据的表达式，如：字面常量、表达式返回值，函数返回值(这个不能是左值引用返回)等等，**右值可以出现在赋值符号的右边，但是不能出现出现在赋值符号的左边，右值不能取地址**。右值引用就是对右值的引用，给右值取别名。
> >
> > **注意：**右值引用地值可以被改变
> >
> > **需要注意的是右值是不能取地址的**，**但是**给右值取别名后，会导致**右值被存储到特定位置，且可以取到该位置的地址**，也就是说例如：不能取字面量10的地址，但是rr1引用后，可以对rr1取地 址，也可以修改rr1。如果不想rr1被修改，可以用const int&& rr1 去引用，即**右值引用本质是个左值，绑定了右值。**
>
> 右值引用和左值引用的区别: :
>
> - 左值可以寻址，而右值不可以。
> - 左值引用只能引用左值，不能引用右值；但是const左值引用既可引用左值，也可引用右值。
> - 右值引用只能右值，不能引用左值；但是右值引用可以move以后的左值。
> - 左值可变,右值不可变（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）。
> - 右值引用有一个重要的性质—只能绑定到一个将要销毁的对象。 因此，我们可以自由地将一个右值引用的资源“移动”到另一个对象中。

#### include头文件的顺序 以及 双引号””和尖括号的区别？

> 对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h。那么要在a.c文件中引用b.h文件，并且要**先引用b.h，后引用a.h**，否则编译器会报变量类型未声明错误。
>
> 这个其实从原理上来说，是因为#include本来就是一个预编译指令，在预编译阶段，编译器会将include引入的文件直接进行原封不动的替换，也就是说在得到汇编文件之前，cpp文件中就已经没有#include、#define等语句了，有的是指定的文件内容。
>
> **双引号和尖括号的区别: 编译器预处理阶段查找头文件的路径不一样。**
>
> 对于使用**双引号包含**的头文件，查找头文件路径的顺序为:
>
> 1. 当前文件所在目录的头文件
> 2. 编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）
> 3. 系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径
>
> 对于使用尖括号包含的头文件，查找头文件的路径顺序为:
>
> 1. 编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）
> 2. 系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径

#### 模板的偏特化与全特化

> [C++ 泛型编程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/105224190)
>
> 模板机制为C++提供了泛型编程的方式，在减少代码冗余的同时仍然可以提供类型安全。 特化必须在同一命名空间下进行，可以特化类模板也可以特化函数模板，但**类模板可以偏特化和全特化，而函数模板只能全特化**。 模板实例化时会优先匹配"模板参数"最相符的那个特化版本。
>
> **模板的声明**
>
> ~~~C++
> //类模板
> template<class T1, class T2>
> class A
> {
>   T1 data1;
>   T2 data2;
> };
> //函数模板
> template<calss T>
> T _max(const T v1, const T v2)
> {
>     return v1 > v2 ? v1 : v2;
> }
> ~~~
>
> **全特化**
>
> ~~~C++
> //类模板
> template<>
> class A<int, int>
> {
>   int data1;
>   int data2;
> };
> //函数模板
> template<>
> T _max(const int v1, const int v2)
> {
>     return v1 > v2 ? v1 : v2;
> }
> ~~~
>
> **偏特化**
>
> ~~~C++
> //类模板
> template<class T1>
> class A<T1, int>
> {
>   T1 data1;
>   int data2;
> };
> ~~~
>
> **为什么需要特化**
>
> > 特化模板代表我们需要特别处理某个类型或者该类特化后的版本比实例化出来的模板效果更佳。
> >
> > 比如说在模拟实现vector时，有三个构造函数：
> >
> > ~~~C++
> > template<>
> > vector(size_t n, const T& value = T());
> > //template<>
> > //vector(int n, const T& value = T());
> > template<class InputIterator>//迭代器构造
> > vector(InputIterator first, InputIterator last);
> > //前两个函数可以去掉template
> > ~~~
> >
> > 如果我们去掉第二个函数模板`template<>vector(int n, const T& value = T());`，此时对于vector<int> v(10, 10)，会去实例迭代器构造版本的函数模板，而不是使用第一个全特化函数模板，从而达不到我们想要的效果。
> >
> > 因为10作为默认类型是int，和size_t是有区别的。而若把(10, 10)看待成(int, int)，显然编译器根据第三个函数模板实例出来的函数比第一个全特化模板函数更加匹配。

#### C/C++类型转换

> ##### C语言
>
> - 隐式类型转换
>
>     编译器在编译阶段自动进行，能转就转，不能转就编译失败。
>
> - 显式强制类型转换
>
>     意义不相近，需要用户自己处理，有的类似隐式类型转换，有的属于截断内存
>
> ~~~C
> void Test ()
> {
>      int i = 1;
>      // 隐式类型转换
>      double d = i;
>      printf("%d, %.2f\n" , i, d);
>      int* p = &i;
>      // 显示的强制类型转换
>      int address = (int) p;
>      printf("%x, %d\n" , p, address);
> }
> ~~~
>
> > - 转换的可视性比较差，所有的转换形式都是以一种相同形式书写，难以跟踪错误的转换。
> >
> > - 有些转换是隐式的，需要注意。
>
> #### C++的类型转换
>
> > C++标准为了加强类型转换的可视性，引入了四种命名的强制类型转换操作符： 
> >
> > static_cast、reinterpret_cast、const_cast、dynamic_cast
>
> ##### 1. static_cast\<type> (value)
>
> > static_cast用于非多态类型的转换（静态转换），编译器隐式执行的任何类型转换都可用 static_cast，但它不能用于两个不相关的类型进行转换
> >
> > **替代隐式类型转换，可转换意义相近的类型**
>
> ~~~C++
> int main()
> {
>   double d = 12.34;
>   int a = static_cast<int>(d);
>   cout<<a<<endl;
>   return 0;
> }
> 
> ~~~
>
> ##### 2. reinterpret_cast\<type>(value)
>
> > reinterpret_cast操作符通常为操作数的位模式提供较低层次的重新解释，用于将一种类型转换 为另一种不同的类型，需要两者内存‘匹配’
> >
> > **替代显式强制类型转换，适用于意义不相干的类型转换，但转换后仍有一定意义**
>
> ~~~C++
> int main()
> {
>  double d = 12.34;
>  int a = static_cast<int>(d);
>  cout << a << endl;
>  // 这里使用static_cast会报错，应该使用reinterpret_cast
>  //int *p = static_cast<int*>(a);
>  int *p = reinterpret_cast<int*>(a);
>  return 0;
> }
> 
> ~~~
>
> ##### 3. const_cast\<type>(value)
>
> > **const_cast最常用的用途就是删除变量的const属性，方便赋值**
>
> ~~~C++
> void Test ()
> {
>   const int a = 2;
>   int* p = const_cast<int*>(&a);
>   *p = 3;
>   cout<<a <<endl;
> }
> 
> ~~~
>
> ##### 拾遗
>
> ![image-20221204175423406](%E5%9B%BE%E7%89%87/README/image-20221204175423406.png)
>
> ~~~
> c++中， const int a 属于常变量， 不存放在常量区，而是在栈上，因为按语法来说，a不能再改变， 所以编译器虽然会使程序中存在a的代码，但不去调用a，而是以宏的方式替代，或保存在寄存器中。所以*p的内容是真的a的地址的内容，a是之前的内容
> 使用volatile 修饰a， 可以禁止编译器优化， 两个都是3
> ~~~
>
> ##### 4. dynamic_cast\<type>(value)▲
>
> > dynamic_cast用于**将一个父类对象的指针/引用转换为子类对象的指针或引用**(动态转换) 
> >
> > 向上转型：子类对象指针/引用->父类指针/引用(不需要转换，赋值兼容规则，语法支持) 
> >
> > 向下转型：父类对象指针/引用->子类指针/引用(用dynamic_cast转型是安全的)
> > 注意：
> >
> > 1. **dynamic_cast只能用于父类含有虚函数的类**
> > 2. dynamic_cast会先检查是否能转换成功，**能成功则转换，不能则返回0**
>
> ~~~C++
> class A
> {
> public:
> 	virtual void f() {}
> };
> class B : public A
> {};
> void fun(A* pa)
> {
> 	// dynamic_cast会先检查是否能转换成功，能成功则转换，不能则返回
> 	B* pb1 = static_cast<B*>(pa);
> 	B* pb2 = dynamic_cast<B*>(pa);
> 	cout << "pb1:" << pb1 << endl;
> 	cout << "pb2:" << pb2 << endl;
> }
> int main()
> {
> 	A a;
> 	B b;
> 	fun(&a); // 地址， nullptr
> 	fun(&b); // 地址， 地址
> 	return 0;
> }
> ~~~
>
> **多继承**
>
> > ptr转为父类指针时，偏移到了正确位置。
>
> ![image-20221204222335917](%E5%9B%BE%E7%89%87/README/image-20221204222335917.png)
>
> 
>
> ##### RTTI
>
> > RTTI：Run-time Type identification的简称，即：运行时类型识别。 
> >
> > C++通过以下方式来支持RTTI： 
> >
> > 1. typeid运算符 
> > 2. dynamic_cast运算符 
> > 3. decltype









# 数据结构

###### map的底层数据结构是什么？为什么不是AVL

> map/set的底层数据结构是红黑树RBT。
>
> AVL树严格要求平衡，左右子树的高度差不能大于1；而RBT要求相对宽松，但也要求最长路径不能大于最短路径两倍
>
> 因为AVL严格要求平衡，则插入删除操作更大概率引发多次旋转操作；而红黑树的插入删除操作小概率引发少次旋转操作
>
> 查找都是LOG级别

# OS

#### 进程与线程的区别，进程通信方式

> 进程是系统资源的最小分配单位，创建进程需要分配地址空间+PCB(process control block)资源，切换复杂
>
> 线程是CPU调度的最小单位，创建线程只需要分配PCB资源，切换简单
>
> 并且，LINUX，进程与线程都是轻量级进程
>
> 进程的通信方式有：较熟悉的有管道，共享内存，不了解的有消息队列

#### 多进程与多线程的区别以及使用场景

> | 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
> | -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
> | 数据共享，同步 | 数据共享复杂，需要使用IPC；数据独立，同步简单                | 因为共享进程数据，数据共享简单，但因此导致同步复杂           | 各有优势 |
> | 内存，CPU      | 占用内存多(每个进程都需要分配进程地址空间)，切换复杂，CPU利用老板低 | 占用内存少(多个线程共用一个进程地址空间)，切换简单，CPU利用率高 | 线程占优 |
> | 创建/销毁/切换 | 创建/销毁/切换复杂，速度慢(创建进程分配的资源多)，原因有：切换PCB，加载内存，打开文件 | 创建/销毁/切换简单，速度快，原因有：仅需要切换PCB，替换寄存器内容，栈内容 | 线程占优 |
> | 可靠性         | 进程间不会互相影响，稳定性高                                 | 一个线程出错会导致整个进程挂掉，稳定性差                     | 进程占优 |
> | 编程/调试      | 编程简单，调试简单                                           | 编程复杂，调试复杂，原因有：线程安全，资源共享               | 进程占优 |
> | 分布式         | 适用于多核多机                                               | 适用于多核                                                   |          |
> | 使用场景       | 系统稳定性要求严格：自动驾驶                                 | 大量计算任务(计算密集)；桌面软件(IO密集)；Web服务器          |          |
>
> [多线程和多进程 及其应用场景_多线程、多进程在实际工程中的用处](https://blog.csdn.net/weixin_39731083/article/details/82015830)
>
> 多进程的优点：
>
> 1. **编程相对容易**；通常不需要考虑锁和同步资源的问题。 
> 2. **更强的容错性**：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。 
> 3. **有内核保证的隔离：数据和错误隔离**。 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。
>
> 多线程的优点：
>
> 1. **创建速度快，方便高效的数据共享** 
>     共享数据：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术。
> 2. **较轻的上下文切换开销** - 不用切换地址空间，不用更改寄存器，不用刷新TLB。 
> 3. **提供非均质的服务**。如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降
>
> 选什么？
>
> 1. **需要频繁创建销毁的优先用线程（进程的创建和销毁开销过大）**
>     这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的
> 2. **需要进行大量计算的优先使用线程（CPU频繁切换）**
>     所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。
>     这种原则最常见的是图像处理、算法处理。
> 3. **强相关的处理用线程，弱相关的处理用进程**
>     什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。
>     一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。
>     当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。
> 4. **多机分布的用进程，多核分布的用线程**
> 5. 一个选择原则：如果多进程和多线程都能够满足要求，那么选择你最熟悉、最拿手的那个。

#### 进程与线程的区别

> - 进程是系统资源的最小分配单位，创建进程需要分配地址空间+PCB(process control block)资源，切换复杂
>
> - 线程是CPU调度的最小单位，创建线程只需要分配PCB资源，切换简单
> - 进程之间数据是独立的，进程通信需要IPC
> - 线程之间共享进程的数据，但也有自己的栈和CPU寄存器，线程通信简单但存在线程安全问题
>
> - 并且，LINUX下，进程与线程都是轻量级进程

#### 进程通信方式

> 管道：匿名管道和命名管道，基于内存文件的通信(管道是内存文件)，自带同步与互斥机制
>
> > 匿名管道适用于具有父子关系的进程，先pipe后fork，匿名管道是纯粹的内存文件，在磁盘上无映射
> >
> > 命名管道适用于无父子关系的进程，先mkfifo后open，命名管道也是内存文件，但在磁盘上有映射(仅映射不刷新)
> >
> > 管道特点：自带同步与互斥机制，生命周期随进程，流式服务，(特殊的)半双工通信，内存级文件
>
> systemV共享内存：基于物理内存的通信(进程通过页表映射到同一块物理内存)，速度最快的进程通信方式，但需要自己保证数据安全
>
> > 不同进程通过页表映射同一块物理内存，是速度最快的进程通信方式
> >
> > 需要自己进行访问控制
>
> systemV消息队列/信号量，socket本地进程通信
>
> > 不熟

#### 僵尸进程是什么，为什么会产生僵尸进程

> 是什么：如果一个进程已经终止，并且它的父进程尚未调用wait()/waitpid()对他进行清理，这时该进程的进程状态称为僵死状态，该进程就是僵尸进程
>
> 产生原因：任何一个子进程(init除外)在退出之后，其对应的PCB不会立马被回收，需要等待父进程读取PCB保存的进程退出信息后才会回收，在进程退出和父进程读取这个时间段，该进程就是状态为Z的僵尸进程
>
> 解决方法：
>
> > 1. 通过信号SIGCHLD，自定义父进程对子进程退出的处理动作，该方法对所有子进程退出生效
> > 2. 将进程转换为孤儿进程，由init进程收养并清理

#### 虚拟内存到物理内存的寻址方式

> Linux中每个进程都有专属页表，页表中存储着虚拟地址到物理地址的映射关系，通过页表中的地址映射，实现 虚拟内存到物理内存 访问

#### 页表的作用

> > 用户级页表和内核级页表
> >
> > 一级页表和二级页表
>
> 页表是一种数据结构，页表存放在内存当中，页表里存放了虚拟地址与物理地址的对应关系，VA到PA的转换过程其实就是MMU查询和解析页表的过程。
>
> 页表的作用：
>
> > 是物理内存非连续分配的基础，将连续的虚拟内存与不一定连续的物理内存连接起来，将内存的分配(OS)与使用(进程)进行解耦
> >
> > 页表中存储着进程的虚拟内存与系统的物理内存的映射关系

#### 进程调度算法

> 为了确定⾸先执⾏哪个进程以及最后执⾏哪个进程以实现最⼤ CPU 利⽤率，计算机科学家已经定义了⼀些算法， 它们是：   
>
> （1）**先到先服务(FCFS)调度算法：** 从就绪队列中选择⼀个最先进⼊该队列的进程为之分配资源，使它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被阻 塞放弃占⽤ CPU 时再重新调度。   
>
> （2）**短作业优先(SJF)的调度算法：** 从就绪队列中选出⼀个估计运⾏时间最短的进程为之分配资源，使它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被 阻塞放弃占⽤ CPU 时再重新调度。   
>
> （3）**时间⽚轮转调度算法：** 时间⽚轮转调度是⼀种最古⽼，最简单，最公平且使⽤最⼴的算法，⼜称 RR(Round robin)调度。每个进程被分配 ⼀个时间段，称作它的时间⽚，即该进程允许运⾏的时间。   
>
> （4）**多级反馈队列调度算法：** 前⾯介绍的⼏种进程调度的算法都有⼀定的局限性。如短进程优先的调度算法，仅照顾了短进程⽽忽略了⻓进程 。 多级反馈队列调度算法既能使⾼优先级的作业得到响应⼜能使短作业（进程）迅速完成。，因⽽它是⽬前被公认的 ⼀种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。   
>
> （5）**优先级调度：** 为每个流程分配优先级，⾸先执⾏具有最⾼优先级的进程，依此类推。具有相同优先级的进程以 FCFS ⽅式执⾏。 可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

#### 判断一个程序是死循环还是死锁

> 死循环：
>
> - 软件状态：未响应
> - CPU：一直保持非0，处于活跃状态
> - 原理：如果主线程出现死循环，那么windows将不能从消息队列中取出消息，并进行处理，所以出现卡死现象。为了验证是这个原因导致界面卡死，打开任务管理器，如果该进程的cpu使用率一直保持非零，比如一直保持在 12%，那么界面卡死的原因是主线程死循环了。
>
> 死锁：
>
> - 软件状态：正在运行
> - CPU：进程的 cpu 使用率一般是0
> - 原理：如果主线程由于跟其他的线程由于争夺资源或者锁，出现了死锁，那么主线程会一直等待资源或者锁，导致主线程不能继续往下执行，分发和处理消息，所以出现卡死。

#### 什么是内存泄漏

> 内存泄漏指因为疏忽或错误造成程序未能释放已经不再使用的内存的情况。内存泄漏并不是指内存在物理上的消失，而是应用程序分配某段内存后，因为设计错误，失去了对该段内存的控制，因而造成了内存的浪费。
>
> 对于C和C++这样的没有Garbage Collection 的语言来讲，我们主要关注两种类型的内存泄漏:
>
> 1. 堆内存泄漏（Heap leak）。堆内存指的是程序执行中依据须要分配通过malloc,realloc new等从堆中分配的一块内存，再是完毕后必须通过调用相应的 free或者delete 删掉。假设程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak.
> 2. 系统资源泄露（Resource Leak）.主要指程序使用系统分配的资源，比如 Bitmap,handle ,SOCKET等没有使用对应的函数释放掉，导致系统资源的浪费，严重可导致系统效能减少，系统执行不稳定。
> 3. 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。
>
> 解决方法:
>
> 1. 使用智能指针;

# 计网

#### http和https的区别

> **端口**
>
> > HTTP的URL由`http://`起始且默认使用端口80
> >
> > HTTPS的URL由`https://`起始且默认使用端口443
>
> **安全性**
>
> > HTTP协议是以明文的方式在网络中传输数据，而HTTPS协议传输的数据则是经过TLS (Transport Layer Security,安全传输层协议)加密后的，HTTPS具有更高的安全性。
> >
> > HTTPS加密采用 CA认证+签名+非对称加密+对称加密 。
>
> **资源消耗**
>
> > HTTPS在TCP三次握手阶段之后，还需要进行SSL(Secure Sockets Layer 安全套接字协议)的handshake，数据加密会消耗服务器资源。

#### HTTPS用到了那些加密技术

> 对称加密
>
> > 密钥只有一个，既可以加密也可以解密，且加密解密速度快，典型有：DES，AES
>
> 非对称加密
>
> > 密钥成对出现，分为公钥和私钥。加密解密使用不同密钥(私钥加密只能由公钥解密，公钥加密只能由私钥加密)，相对对称加密速度较慢，典型有：RSA，DSA
>
> CA认证签名+非对称加密+对称加密
>
> > 服务器向CA机构申请得到CA私钥加密后的证书，该证书里有服务器公钥
> >
> > 客户端链接服务器时会得到服务器的CA证书，使用公布的CA公钥来验证该证书的合法性
> >
> > 若证书合法，则证书里的服务器公钥要是合法的，此时客户端使用该公钥加密自己的对称密钥，返回给服务器
> >
> > 服务器得到后使用服务器私钥解密，这样CS都具有对称密钥，使用该密钥进行加密解密

#### 打开一个网页使用到了哪些协议？

> [一次完整的HTTP请求过程是怎么样的呢？](https://zhuanlan.zhihu.com/p/161560683)
>
> 概述
>
> > 1. **浏览器进行DNS域名解析，得到对应的IP地址**
> > 2. **根据这个IP，找到对应的服务器建立连接（三次握手）**
> > 3. **建立TCP连接后发起HTTP请求（一个完整的http请求报文）**
> > 4. **服务器响应HTTP请求，浏览器得到html代码（服务器如何响应）**
> > 5. **浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）**
> > 6. **浏览器对页面进行渲染呈现给用户**
> > 7. **服务器关闭TCP连接（四次挥手）**
> > 8. **还可能用到ARP，NAT，ICMP协议**
>
> 详情
>
> > DNS查找IP：浏览器缓存，OS缓存，hosts文件，DNS服务器
> >
> > TCP协议：三次握手
> >
> > IP协议：路由转发
> >
> > HTTP协议：HTTP请求/响应
> >
> > ARP协议：IP转MAC地址
> >
> > NAT协议：IP转换
> >
> > ICMP协议：错误审查

#### DNS过程详情

> 域名的解析是⼀个从右向左的过程，并且域名都隐藏了一个默认的根域名服务器`.`
>
> `. -> .com -> google.com. -> www.google.com . `
>
> - 首先会在**浏览器的DNS缓存**中去查询是否有对应的记录，如果查询到记录就可以直接得到对应的IP地址，则完成解析。
> - 如果在浏览器的DNS缓存中没有找到，就会去查询**操作系统中的DNS缓存**，如果查询到对应的IP地址，则完成解析。
> - 如果在操作系统的DNS缓存中没有找到，就会去查找**本地的hosts文件**，如果查询到对应的IP地址，则完成解析。
> - 如果在本地的hosts文件中也没有找到，就会去**本地DNS服务器**中查找。本地DNS服务器IP地址一般由本地网络服务商提供，如电信、移动等公司，一般通过DHCP自动分配。目前使用的比较多的是谷歌提供的公用NDS 8.8.8.8和国内公用DNS 114.114.114.114。如果在本地DNS服务器中有对应域名的缓存，直接返回对应的IP地址，则完成解析。
> - 如果本地DNS服务器中仍然没有找到，那么本地DNS服务器就会拿着域名去**根DNS服务器**中询问，根DNS服务器会告诉本地DNS顶级域名服务器的IP地址。
> - 本地DNS拿到顶级域名服务器的IP地址后，就会拿着域名去找**顶级DNS服务器**，顶级域名服务器会告诉本地DNS权威域名服务器的IP地址。
> - 本地DNS服务器拿着域名去**权威域名服务器**中，查询域名对应的IP地址，最终将该域名对应的IP地址返回给浏览器，此时整个域名解析过程就完成了。

#### TCP四次挥⼿中，time-wait状态，close-wait状态，在哪⼀个阶段？

> 四次挥手
>
> > 1. 客户端发送 FIN
> >     
> >
> > 2. 服务器返回 ACK 号
> >
> >     
> >
> > 3. 服务器发送 FIN   
> >
> > 4. 客户端返回 ACK 号  
>
> 状态变化(建议画图)
>
> > 客户端发送FIN：⽤来申请关闭客户端到服务器的数据传送，此时 客户端进⼊**FIN_WAIT_1状态**，等待服务器发送ACK
> >
> > 服务器收到FIN：服务器收到客户端发送的FIN后，就会进入**CLOSE_WAIT状态**
> >
> > 服务器发送ACK：告知客户端自己收到了C->S链接断开的请求，此时 客户端发送服务器读取的链接关闭
> >
> > 客户端收到ACK：客户端进入**FIN_WAIT_2状态**，此时 客户端发送服务器读取的链接关闭
> >
> > 
> >
> > 服务器发送FIN：⽤来申请关闭服务器到客户端的数据传送，此时服务器进入**LASE_ACK状态**，等待客户端发送最后的ACK
> >
> > 客户端收到FIN：客户端收到服务器断开链接请求，客户端进入**TIME_WAIT状态**，并发送一个ACK
> >
> > 客户端发送ACK：等待两个MSL时间关闭S->C链接，然后关闭服务器发送客户端读取的链接
> >
> > 服务器收到ACK：关闭服务器发送客户端读取的链接
> >
> > 服务器没收到ACK：重新发送FIN
>
> ![image-20230724113908431](%E5%9B%BE%E7%89%87/README/image-20230724113908431.png)

#### TCP粘包拆包

> 包：应用层数据包
>
> 产生粘包的原因：
>
> > 应用层交给TCP的数据，是先放在TCP发送缓冲区，再由TCP协议控制发送的。而TCP发送数据时依赖滑动窗口，这就导致在发送时，数据报不一定是一个应用层数据包。
> >
> > 那么TCP接收端在接收到数据时，因为是面向字节流+没有报文长度字段，导致接收端也无法分辨是否是一个数据包，只能按照32位序列号进行排序。
> >
> > 在应用层读取时，需要从TCP接收缓冲区读取，TCP是面向字节流的，导致应用层读到的是一串数据，这些数据不能保证正正好好是一个数据包，只能保证宏观上有序。
> >
> > TCP的读取和发送是有水位线概念的，到达一定字节时，才允许从TCP读取和发送，粘包也能解决频繁IO。
>
> 如何解决粘包问题：
>
> > 粘包问题是在应用层解决的，一可以通过协议表明一个数据包的长度，二可以明确数据包之间的分隔标识，通过标识切割。
> >
> > 如HTTP解决粘包问题使用的是 定长报头+正文长度字段 来保证读取一个完整HTTP数据包。

#### TCP拥塞控制和流量控制的区别

> 拥塞控制是对整个通信网络来说的，避免过多的数据注入到网络中，使网络拥塞进而大量丢包，拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低⽹络传输性能有关的所有因素。
>
> 流量控制是对一条TCP通信链接来说的，是个端到端的问题，控制发送数据速率，确保接收端来得及接收。
>
> 发送窗口受制于拥塞控制和流量控制。

#### TCP建立连接为什么是三次握手，而不是两次握手？

> 先说结论：三次握手是验证双方建立可靠通信的**最少次数**，并且能够将建立连接失败时的异常链接挂在客户端上(**风险转移**)
>
> 为什么不是两次握手：
>
> > 一次握手：客户端发送SYN，收不到ACK，无法确认C->S链接是否正常，而且只建立了单向通信，且存在**SYN洪泛风险**
> >
> > 二次握手：服务端收到SYN就会建立链接，进入ESTABLISHED状态，而客户端需要收到ACK才会建立链接，若客户端拒收ACK不建立链接，那么**服务器就建立了一个失效的链接，浪费服务器资源**。而且服务器无法确认S->C链接是否正常
> >
> > 三次握手：正常的三次握手CS双方都能确认通信正常，而且客户端比服务端先进入ESTABLISHED状态，客户端成本大于服务端成本

#### 挥手为什么需要有TIME_WAIT状态

> 先说结论：**在正常情况下，确保TCP服务器进程可以收到最后一个TCP确认报文段而进入关闭状态，确保客户端在服务端之后断开链接**
>
> TIME_WAIT状态存在的必要性：
>
> - 客户端在进行四次挥手后进入TIME_WAIT状态，如果第四次挥手的报文丢包了，客户端在一段时间内仍然能够接收服务器重发的FIN报文并对其进行响应，**能够较大概率保证最后一个ACK被服务器收到**。
> - 客户端发出最后一次挥手时，双方历史通信的数据可能还没有发送到对方。因此客户端四次挥手后进入TIME_WAIT状态，**还可以保证双方通信信道上的数据在网络中尽可能的消散。使下一个新的TCP连接中，不会出现旧连接中的报文段**
> - 引入TIME_WAIT状态就是**争取让主动发起四次挥手的客户端维护这个成本**，如果第四次挥手后，客户端直接进入CLOSED状态，那么第四次挥手ACK丢包，服务器会多次重发第三次挥手FIN，直到关闭。而TIME_WAIT却能在丢包后使客户端响应重发的第三次挥手FIN，这样就使得客户端最后断开链接。

#### TCP协议如何保证数据可靠性

> 滑动窗口：应用层数据包会被分割成TCP认为的最合适的数据块，即使出错，也只会重发数据包的一部分
>
> 流量控制和拥塞控制：可以控制TCP发送端的发送速率，确保TCP接收端的正常接收，避免接收不了而舍弃的包丢失
>
> 校验和：能够验证一个数据块在传输过程中是否发生修改
>
> 32位序列号和32确认序列号：能够将数据块有序排放，把有序数据按字节流的方式提交给应用层
>
> 超时重传和快重传：确保丢失的数据的重新发送

#### TCP异常情况

##### 进程终止

当客户端正常访问服务器时，如果客户端进程突然崩溃了，此时建立好的连接会怎么样？

当一个进程退出时，该进程曾经打开的文件描述符都会自动关闭，因此当客户端进程退出时，相当于自动调用了close函数关闭了对应的文件描述符，此时双方操作系统在底层会正常完成四次挥手，然后释放对应的连接资源。也就是说，**进程终止时会释放文件描述符，TCP底层仍然可以发送FIN，和进程正常退出没有区别。**

##### 机器重启

当客户端正常访问服务器时，如果将客户端主机重启，此时建立好的连接会怎么样？

当我们选择重启主机时，操作系统会先杀掉所有进程然后再进行关机重启，**因此机器重启和进程终止的情况是一样的**，此时双方操作系统也会正常完成四次挥手，然后释放对应的连接资源。

##### 机器掉电/网线断开

当客户端正常访问服务器时，如果将客户端突然掉线了，此时建立好的连接会怎么样？

**当客户端掉线后，服务器端在短时间内无法知道客户端掉线了，因此在服务器端会维持与客户端建立的连接，但这个连接也不会一直维持，因为TCP是有保活策略的。**

- 服务器会定期检查客户端的存在状况，检查对方是否在线，如果**连续多次都没有收到ACK应答，此时服务器就会关闭这条连接**。
- 此外，客户端也可能会定期向服务器“报平安”，如果**服务器长时间没有收到客户端的消息，此时服务器也会将对应的连接关闭**。

其中服务器定期询问客户端的存在状态的做法，叫做**基于保活定时器的一种心跳机制**，是由TCP实现的。此外，应用层的某些协议，也有一些类似的检测机制，例如基于长连接的HTTP，也会定期检测对方的存在状态。

#### socket套接字什么情况下可读可写

> **可读：**
>
> - socket接收缓冲区中已经接收的数据字节数**大于等于socket接收缓冲去低水位标记值**，则对该状态的socket进行读操作不会阻塞，并返回一个实际读取值。TCP接收低水位默认为1，发送低水位默认为2048.
> - socket对应的读功能(当前端从socket读取的功能，或者说当前端接收到FIN请求)关闭，此时对该socket进行读操作不会阻塞并返回。
> - 当套接字为监听套接字，且收到了connect请求，即已经完成的连接数非0，此时使用accep读取该套接字(获取请求)不阻塞并且返回一个socket。
> - 有一个socket有异常错误条件待处理.对于这样的socket的读操作将不会阻塞,并且返回一个错误(-1),errno则设置成明确的错误条件.这些待处理的错误也可通过指定socket选项SO_ERROR调用getsockopt来取得并清除。
>
> **可写：**
>
> - socket的发送缓冲区中的数据字节大于等于该socket的发送缓冲区低水位标记的当前大小。对这样的socket的写操作将不阻塞并返回一个大于0的值(也就是返回准备好写入的数据)。我们可以用SO_SNDLOWAT socket选项来设置该socket的低水位标记。对于TCP和UDPsocket而言，其缺省值为2048。
> - 该连接的写这一半关闭(当前端主动发送FIN请求)。对这样的socket的写操作将产生SIGPIPE信号，该信号的缺省行为是终止进程。
> - 有一个socket异常错误条件待处理.对于这样的socket的写操作将不会阻塞并且返回一个错误(-1),errno则设置成明确的错误条件.这些待处理的错误也可以通过指定socket选项SO_ERROR调用getsockopt函数来取得并清除;
>
> **参考：**
>
> - 该套接字的接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的大小；
> - 该套接字的读半部关闭（也就是收到了FIN），对这样的套接字的读操作将返回0（也就是返回EOF）；
> - 该套接字是一个监听套接字且已完成的连接数不为0；
> - 该套接字有错误待处理，对这样的套接字的读操作将返回-1。
> - 
> - 该套接字的发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区低水位标记的大小；
> - 该套接字的写半部关闭，继续写会产生SIGPIPE信号；
> - 非阻塞模式下，connect返回之后，该套接字连接成功或失败；
> - 该套接字有错误待处理，对这样的套接字的写操作将返回-1。

#### UDP调用connect有什么作用

> [UDP编程有必要调用connect吗 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/380109394)
>
> - 效率变高
>
>     > sendto/recvfrom参数远多于send/recv，这四个函数都是系统调用，在调用次数相等的情况下，前两个函数的形参大小是大于后两个，即用户态切换到内核态时，需要copy的数据变多，效率降低。反之效率变高。
>
> - 消耗变少
>
>     > sendto/recvfrom的通信是基于形参里的sockaddr结构体的，进入sendto系统调用后，OS需要分配空间存储形参；退出后，OS需要释放空间，每一次调用sendto都会重复这个步骤。分配->发送->释放->分配->发送->释放->……
>     >
>     > 而connect会在内核中维护一个"链接"，当多次向同一个对端发送数据时，OS只会产生一次分配与释放。分配->发送->发送->发送->……->释放。
>
> - 能够接收到错误信息
>
>     > ECONNREFUSED错误，相信大家在写UDP socket程序的时候，都有遇到 这个“连接错误”的提示。UDP不是无连接的吗？怎么会有连接错误呢？而且如果我不调用connect函数，这个错误就不会报上来的，这是为什么呢？
>     >
>     > 当一个 UDP socket 去 connect 对端 时，并没有发送任何的数据包，其效果仅仅是在内核建立了一个五元组映射，该映射的作用正是为了和 UDP 带外的 ICMP 控制通道捆绑在一起。当调用了connect之后，内核协议栈就维护了一个从源到目的地的单向连接。当下层有ICMP错误信息返回时，内核就可以根据这个五元组找到是那个UDP socket发的包失败了，进而可以把错误信息传输给该socket，应用程序就可以得到该错误信息了。
>     >
>     > 但是对于一个没有connect的udp socket， 内核将数据发出去之后，没有维护五元组，ICMP有错误返回的时候，内核就找不到是哪个 udp socket出的错，所以用户层也就无法收到这个错误信息的。
>
> [udp调用connect有什么作用？_C咖咖的博客-CSDN博客](https://blog.csdn.net/janeqi1987/article/details/46737135)
>
> - UDP中可以使用connect系统调用
>
> - UDP中connect操作与TCP中connect操作有着本质区别。TCP中调用connect会引起三次握手，client与server建立连结。UDP中调用connect内核仅仅把对端ip&port记录下来。
>
> - UDP中可以多次调用connect，TCP只能调用一次connect。UDP多次调用connect有两种用途：（1）指定一个新的ip&port连结，直接设置connect第二个参数即可。（2）断开和之前的ip&port的连结，需要将connect第二个参数中的sin_family设置成 AF_UNSPEC即可。
>
> - UDP中使用connect可以提高效率。原因如下：
>
>     > 普通的UDP发送两个报文内核做了如下：#1建立连结#2发送报文#3断开连结#4建立连结#5发送报文#6断开连结
>     >
>     > 采用connect方式的UDP发送两个报文内核如下处理：#1建立连结#2发送报文#3发送报文#....#断开链接。另外一点，每次发送报文内核都由可能要做路由查询。
>
> - 采用connect的UDP发送接受报文可以调用send、rite和recv、read操作，当然也可以调用sendto、recvfrom。调用sendto的时候第五个参数必须是NULL，第六个参数是0，调用recvfrom、recv、read系统调用只能获取到先前connect的ip&port发送的报文。
>
> - UDP中使用connect的好处：
>
>     > - 会提升效率，减少OS消耗。前面已经描述了。
>     > - 高并发服务中会增加系统稳定性。原因：假设client A 通过非connect的UDP与server B，C通信。B，C提供相同服务。为了负载均衡，我们让A与B、C交替通信。A与 B通信IPa:PORTa <----> IPb:PORTb；A与 C通信IPa:PORTa'<---->IPc:PORTc。假设PORTa与 PORTa'相同了(在大并发情况下会发生这种情况)，那么就有可能出现A等待B的报文，却收到了C的报文，导致收报错误。解决方法内就是采用connect的UDP通信方式，在A中创建两个udp，然后分别connect到B、C。
